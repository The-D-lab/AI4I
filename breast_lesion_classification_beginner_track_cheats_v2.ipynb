{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <b> Make sure you are running this in google colab.</b>\n",
        "Go to the link: https://drive.google.com/drive/folders/11eX89jZEuR0yWtBWwzLuIZDqQmsyXEcT?usp=sharing and click on <i> \"add the shortcut to My Drive\" </i>. This will add the shortcut to My Drive.\n",
        "\n",
        "For a detailed step by step procedure, please open this link to follow the instructions: https://docs.google.com/document/d/1uhH_5W_Aoa8zlyMSvmU_yuhyJJgR6-7l/edit?usp=sharing&ouid=107456846675416400203&rtpof=true&sd=true\n",
        "\n",
        "<b> Before starting your notebook, click on Runtime: Change Runtime to GPU. If not possible, proceed with the GPU runtime. </b>"
      ],
      "metadata": {
        "id": "6_Qnyn_-tyXF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtN4zFK7xfOn"
      },
      "source": [
        "# Deep Learning for beginners \n",
        "## Classification of suspicious breast lesions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-QPKKNdxfOz"
      },
      "source": [
        "### This is a private dataset of Contrast Enhanced Mammography (CEM) kindly supplied by MUMC+ for the purposes of this course only. Please make sure you delete image data after the workshop."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started : Setting up the google drive and installing some packages"
      ],
      "metadata": {
        "id": "vb9BDaoHxpsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "-RdFrQY72AV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q livelossplot"
      ],
      "metadata": {
        "id": "Gm7KYOO53iNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r50oHO1QxfO1"
      },
      "source": [
        "## Description of the dataset\n",
        "* The dataset is comprised of 997 MUMC patients that were recalled after a screening mammography.\n",
        "* Each patient has two views of CEM images  - Caudal-cranial (CC) and mediolateral oblique view (MLO)\n",
        "* Each view has two types of image - the low energy image (almost like a standard mammo) and the recombined image\n",
        "* Masses have pathological confirmation of status, labeled 0 for benign and 1 for malignant\n",
        "* The data has been resized to 256*256 crop around the tumor while maitaining the same greyscale values\n",
        "* the arrays have two channels containing the (1) low energy image and (2) the recombined low and high energy images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5u4tvA_xfO2"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1NcUiIikQX4jxCQXgCLkvQHRKlYj8g6ll)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa6PG24PxfO4"
      },
      "source": [
        "#### <b>Notebook structure:</b>\n",
        "The script will take you through 5 steps where you'll learn how to train the models. <br>\n",
        " - <b>1. Importing libraries. </b> \n",
        " - <b>2. Getting Your Data Ready. </b> \n",
        " - <b>3. Define the Network. </b> \n",
        " - <b>4. Train your network. </b> \n",
        " - <b>5. Test your network. </b> \n",
        "\n",
        "<br> \n",
        "\n",
        "\n",
        "#### <b>Filling in Missing Values:</b>\n",
        "\n",
        "You will have to fill in some missing values in the notebook. They will help you to better understand the deep learning workflow.\n",
        "\n",
        "#### <b> If you get stuck you can always open the \"cheat\" notebook, but where's the fun in that? </b> :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJbDQFoXxfO7"
      },
      "source": [
        "## 1. Import librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO513u-GxfPA"
      },
      "outputs": [],
      "source": [
        "#desactivate warnings \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#import utilities\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from glob import glob \n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "#import images \n",
        "from skimage.io import imread \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#import \n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#import keras functions\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Input, Concatenate, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from livelossplot.tf_keras import PlotLossesCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh9KWp4UxfPC"
      },
      "source": [
        "## 2. Getting your data ready"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Visualizing the data contents"
      ],
      "metadata": {
        "id": "Tc5GSJpqvXK2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "sw0Za7p3xfPE"
      },
      "outputs": [],
      "source": [
        "folder_pth = r\"/content/drive/MyDrive/breast_lesion_classification\"\n",
        "\n",
        "csv_path = os.path.join(folder_pth, r\"df_for_workshop.csv\")\n",
        "info_csv = pd.read_csv(csv_path)\n",
        "print(info_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY2frPtOxfPF"
      },
      "outputs": [],
      "source": [
        "#Assign the target variable\n",
        "classification = info_csv.classification\n",
        "print(\"The targets in the classification variable:\")\n",
        "classification.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSS5iZyJxfPF"
      },
      "outputs": [],
      "source": [
        "#load images\n",
        "image_ID = info_csv[\"image_ID\"] # getting image IDs from the csv file\n",
        "path_npy = os.path.join(folder_pth, r\"dataset_for_workshop\")\n",
        "\n",
        "\n",
        "# reading the training patches in the Variable X using np.load\n",
        "X = []\n",
        "for image_id in tqdm(list(image_ID)):\n",
        "    X.append(np.load(os.path.join(path_npy,image_id)))\n",
        "\n",
        "X = np.array(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cxAH380xfPH"
      },
      "outputs": [],
      "source": [
        "print(\"the size of the dataset is:\", X.shape)\n",
        "\n",
        "#extract shape parameter\n",
        "IMAGE_SIZE = X[0].shape\n",
        "N_IMAGES = len(X)\n",
        "print(\"Number of images:\", N_IMAGES)\n",
        "print(\"Image size:\",IMAGE_SIZE[:2])\n",
        "print(\"Number of channels:\", IMAGE_SIZE[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsB2ffySxfPI"
      },
      "outputs": [],
      "source": [
        "#we can split in testing and training with train_test_split function from sklearn\n",
        "# do a 70/30 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,classification,test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOpMQeFZxfPJ"
      },
      "source": [
        "## 2.2. Making Training and Testing Data Arrays based on the train_test_split\n",
        "We have split train and test data into two folders. Make two train and test arrays containing the image patches of size 256 x 256."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMZkywPKxfPK"
      },
      "outputs": [],
      "source": [
        "train_ID = os.listdir(os.path.join(folder_pth, \"train\"))\n",
        "X_train = []\n",
        "y_train = []\n",
        "for image_id in tqdm(list(train_ID)):\n",
        "    X_train.append(np.load(os.path.join(folder_pth, \"train\",image_id)))\n",
        "    y_train.append(classification[image_ID == image_id].values[0])\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "test_ID = os.listdir(os.path.join(folder_pth, \"test\"))\n",
        "X_test = []\n",
        "y_test = []\n",
        "for image_id in tqdm(list(test_ID)):\n",
        "    X_test.append(np.load(os.path.join(folder_pth, \"test\",image_id)))\n",
        "    y_test.append(classification[image_ID == image_id].values[0])\n",
        "\n",
        "X_test = np.array(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCib_WZyxfPL"
      },
      "outputs": [],
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrzTtix9xfPL"
      },
      "outputs": [],
      "source": [
        "#extract shape parameter\n",
        "IMAGE_SHAPE = X_train[0].shape\n",
        "IMAGE_SIZE = X_train[0].shape[1]\n",
        "print(\"Image shape:\",IMAGE_SHAPE[:2])\n",
        "print(\"Number of channels:\", IMAGE_SHAPE[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFOEXoT4xfPL"
      },
      "source": [
        "## 2.3: Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDzuEe-hxfPL"
      },
      "outputs": [],
      "source": [
        "#normalisation coef, first mean second std\n",
        "norm_coeff_re=[897,728] #norm_coeff_re : for the recombined image, first channel of the array\n",
        "norm_coeff_le=[770,847] #norm_coeff_le : for the low energy image, second channel of the array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ5nZQCDxfPM"
      },
      "outputs": [],
      "source": [
        "#normalize images (use coefficients)\n",
        "new_X_train = []\n",
        "for i, x in enumerate(X_train):\n",
        "    x_le = (x[:,:,1]-norm_coeff_le[0])/norm_coeff_le[1] # z-score\n",
        "    x_re = (x[:,:,0]-norm_coeff_re[0])/norm_coeff_re[1] # z-score\n",
        "    new_X_train.append(np.concatenate((np.expand_dims(x_re, axis=2), np.expand_dims(x_le, axis=2)),axis = 2)) #concatenate channels on the 3rd axis\n",
        "    \n",
        "new_X_test = []\n",
        "for i, x in enumerate(X_test):\n",
        "    x_le = (x[:,:,1]-norm_coeff_le[0])/norm_coeff_le[1] # z-score\n",
        "    x_re = (x[:,:,0]-norm_coeff_re[0])/norm_coeff_re[1] # z-score\n",
        "    new_X_test.append(np.concatenate((np.expand_dims(x_re, axis=2), np.expand_dims(x_le, axis=2)),axis = 2)) #concatenate channels on the 3rd axis\n",
        "\n",
        "new_X_train = np.array(new_X_train)\n",
        "new_X_test = np.array(new_X_test)\n",
        "\n",
        "print(\"new_X_train shape: \", new_X_train.shape)\n",
        "print(\"new_X_test shape: \", new_X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhtbMxRIxfPM"
      },
      "source": [
        "What you should see: <br>\n",
        "new_X_train shape:  (1395, 256, 256, 2) <br>\n",
        "new_X_test shape:  (599, 256, 256, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHpl3E1WxfPM"
      },
      "outputs": [],
      "source": [
        "#using only one channel for the Xception model\n",
        "X_train = np.expand_dims(new_X_train[:,:,:,0],axis=3)\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = np.expand_dims(new_X_test[:,:,:,0],axis=3)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Visualizing the Slices"
      ],
      "metadata": {
        "id": "uN9GRmjzzW3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VUXKbmgxfPN"
      },
      "outputs": [],
      "source": [
        "#sanity check: check how the data looks like, change the range parameters and X_test for X_train\n",
        "\n",
        "for i in range(10):\n",
        "    idx = np.random.randint(0, len(X_test))\n",
        "    plt.figure()\n",
        "    plt.imshow(np.squeeze(X_test[idx,:,:]/255))\n",
        "    plt.title(\"Label - \" + str(y_test[idx]))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b4y3sczxfPN"
      },
      "source": [
        "## 3. Define the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtE-CAWRxfPO"
      },
      "outputs": [],
      "source": [
        "#enter the number of units for the dense layer\n",
        "\n",
        "def CNN_xception(input_shape):\n",
        "    base_model = Xception(weights=None, include_top=False,input_shape=input_shape,pooling = 'avg')\n",
        "    #hint : change the last layers if you built your own model\n",
        "    x = base_model.output\n",
        "    print(x.shape)\n",
        "    x = Dense(1024, activation='relu')(x) #choose number of units for dense layer, 1024 for pre-loaded weights\n",
        "    print(x.shape)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    print(predictions.shape)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "callbacks_list = [PlotLossesCallback()]\n",
        "\n",
        "model1 = CNN_xception((IMAGE_SIZE, IMAGE_SIZE,1))\n",
        "\n",
        "#model architecture\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4sV-4SBxfPP"
      },
      "source": [
        "### 4. Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Mode 1: Training the model using GPU"
      ],
      "metadata": {
        "id": "AqJ0-6Oo0ZlK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_AiwgfBxfPP"
      },
      "outputs": [],
      "source": [
        "#optimizer can be found https://keras.io/optimizers/\n",
        "model1.compile(optimizer= Adam(lr=0.00001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#choose batch size and epochs number\n",
        "history =model1.fit(X_train/255,  np.array(y_train), batch_size=4, epochs=2,\n",
        "                                      validation_data=( X_test/255, np.array(y_test)),callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-jrzLk5xfPQ"
      },
      "source": [
        "### 4.2: Mode 2: Use the pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFKuY89WxfPQ"
      },
      "outputs": [],
      "source": [
        "model1.load_weights(os.path.join(folder_pth, r\"checkpoint.hdf5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRthDL-1xfPQ"
      },
      "source": [
        "## 5: Test the model\n",
        "### 5.1 Get the Predictions on the Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCDwRtZSxfPQ"
      },
      "outputs": [],
      "source": [
        "# ROC validation plot \n",
        "\n",
        "predictions = []\n",
        "for x in tqdm(X_test):\n",
        "    predictions.append(model1.predict(np.expand_dims(x,axis=0)/255))\n",
        "predictions =  np.array(predictions).flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 plot the ROC curve"
      ],
      "metadata": {
        "id": "presRqNq3avH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTqp8R0ixfPR"
      },
      "outputs": [],
      "source": [
        "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, predictions) #use roc_curve function from sklearn library\n",
        "area_under_curve = auc(false_positive_rate, true_positive_rate) #use auc function from sklearn library\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Classification Report"
      ],
      "metadata": {
        "id": "YvsHLHuh6QA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification_threshold = 0.5\n",
        "true_labels = y_test\n",
        "predicted_labels = predictions > classification_threshold\n",
        "\n",
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "id": "1hClM20I6Onj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl74mOx0xfPR"
      },
      "source": [
        "### 5.4 Test the model with test time augmentation (TTA) to improve results\n",
        "\n",
        "Documentation: https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0sLxYgfxfPR"
      },
      "outputs": [],
      "source": [
        "#can change the transformations see ImageDataGenerator documentations\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhUumJCgxfPS"
      },
      "outputs": [],
      "source": [
        "#choose number of times you apply transformation to the test set\n",
        "tta_idx = 4\n",
        "tta_prediction = np.empty((tta_idx,) + predictions.shape[:] + (1,)) #initialize with the former predictions\n",
        "for i in tqdm(range(tta_idx)):\n",
        "    val_it_plain = train_datagen.flow(X_test,y_test, batch_size=len(y_test), shuffle = False)\n",
        "    x,y = val_it_plain.next()\n",
        "    tta_prediction[i] = model1.predict(x)\n",
        "\n",
        "tta_prediction=np.array(tta_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlRCFqnSxfPT"
      },
      "outputs": [],
      "source": [
        "mean_prediction = np.mean(tta_prediction,axis = 0).reshape(len(y_test))\n",
        "\n",
        "# ROC validation plot with TTA\n",
        "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, mean_prediction) #use roc_curve function from sklearn library\n",
        "area_under_curve = auc(false_positive_rate, true_positive_rate) #use auc function from sklearn library\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_threshold = 0.5\n",
        "true_labels = y_test\n",
        "predicted_labels = mean_prediction > classification_threshold\n",
        "\n",
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "id": "gbFqFpwy9Bcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L60PLDWFxfPT"
      },
      "source": [
        "If you arrived here, well done ! Now you can play with the data and try new models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TleKRXcpxfPT"
      },
      "source": [
        "# Second part: try to implement your own model with 2 channels\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AogCRMGtxfPT"
      },
      "source": [
        "Suggestion of changes: <br>\n",
        "* you can load separetly the views (CC and MLO) and train on those subsets\n",
        "* during pre-processing of the data you can implement an other normalization method, filtering, rebinning, data augmentation\n",
        "* for training the model you can try a different base model: vgg16, densenet101, inception ... and pre-load the weights from ImageNet\n",
        "* after loading a base model, you can choose to add some more layer, change the number of units\n",
        "* try different parameters, you can change the learning rate, the loss function, the batch size, the optimizer... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmCi4u5MxfPU"
      },
      "source": [
        "## In case the images cannot be load entirely in the memory\n",
        "The generator function load the data batch by batch. To train the model, it needs to be used with model1.fit_generator() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcB44cSlxfPU"
      },
      "outputs": [],
      "source": [
        "# def generator(gen_type, batch_size = 10):\n",
        "    \n",
        "#     assert gen_type in [\"train\",\"test\"], \"Allowed gen_type: train or test\"\n",
        "    \n",
        "#     ids = os.listdir(gen_type) \n",
        "    \n",
        "#     while True:\n",
        "        \n",
        "#         X = []\n",
        "#         y = []\n",
        "    \n",
        "#         offset = np.random.randint(0,len(ids)-batch_size)\n",
        "#         batch_ids = ids[offset:offset+batch_size] \n",
        "        \n",
        "#         for image_id in batch_ids:\n",
        "    \n",
        "#             X.append(np.load(os.path.join(gen_type,image_id))) #possible that there might be cache files and stuff, so may be check the extension as well for train_Id\n",
        "#             y.append(classification[image_ID == image_id].values[0])\n",
        "            \n",
        "        \n",
        "#         yield np.array(X),np.array(y)\n",
        "            \n",
        "# train_gen = generator(\"train\")\n",
        "# test_gen = generator(\"test\")\n",
        "\n",
        "# model1.fit_generator(train_gen, steps_per_epoch=2000,\n",
        "#     epochs=20,\n",
        "#     validation_data=test_gen,\n",
        "#     validation_steps=800)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "breast_lesion_classification_beginner_track_cheats_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}